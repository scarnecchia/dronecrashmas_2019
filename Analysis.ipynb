{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drone Crashmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import seaborn as sns\n",
    "import json\n",
    "from urllib.parse import urlsplit\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "import http.client\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client[\"twitterdb\"]\n",
    "collection = db.droneCrashmas2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = {\n",
    "        #convert created_at to date\n",
    "        '$project': {\n",
    "            '_id': 0, \n",
    "            'id': 1, \n",
    "            'created_at': {\n",
    "                '$dateFromString': {\n",
    "                    'dateString': '$created_at'\n",
    "                }\n",
    "            }, \n",
    "            'user': 1, \n",
    "            'entities': 1, \n",
    "            'lang': 1, \n",
    "            'text': 1, \n",
    "            'retweeted_status': 1\n",
    "        }\n",
    "    }\n",
    "\n",
    "match = {\n",
    "        '$match': {\n",
    "            'created_at': {\n",
    "                '$lte': dt.datetime(2020, 1, 1, 0, 0, 0, tzinfo=dt.timezone.utc)\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = collection.aggregate([projection, match])\n",
    "df =  pd.DataFrame(list(cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_at'] = df['created_at'].dt.tz_localize('UTC')\n",
    "df['created_at'] = df['created_at'].dt.tz_convert('US/Eastern')\n",
    "df = df[(df['created_at'] >= '2019-12-21 00:00:00') & (df['created_at'] <= '2019-12-31 23:59:59')]\n",
    "df['hour'] = df['created_at'].dt.hour\n",
    "df['day_of_week'] = df['created_at'].dt.dayofweek\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()\n",
    "df = df[~df['text'].str.contains('iraq|afghanistan|libya|syria|airstrike|soleimani|suleimani|qaeda|terrorist', na=False)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lang'] = df['lang'].replace('en-gb', 'en-GB')\n",
    "df['lang'] = df['lang'].replace('en-GB', 'en')\n",
    "df_en = df.loc[df['lang'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashmas = pd.DataFrame()\n",
    "crashmas = df[df['text'].str.contains('dad|brother|hair|crash|dog|cat|roof|mom|mother|grandmother|grandma|sister|grandfather|grandpa|tree|lake|pond|ocean|lost|crashed|broken|broke|vanished|uncle', na=True)].reset_index()\n",
    "crashmas = crashmas.loc[crashmas['lang'] == 'en']\n",
    "crashmas = crashmas[~crashmas['screen_name'].str.contains('mountainherder|faineg', na=False)]\n",
    "crashmas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashmas_2 = crashmas.groupby(crashmas['created_at'].rename('Date')).size().reset_index(name='Number of Tweets')\n",
    "crashmas_2 = crashmas_2.set_index(['Date'])\n",
    "crashmas_2.index = pd.to_datetime(crashmas_2.index, unit='s')\n",
    "crashmas_resampled = crashmas_2.resample('H').sum().reset_index()\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"darkgrid\", {'axes.facecolor':'.95'})\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "plt.xticks(rotation=45)\n",
    "lp = sns.lineplot(data=crashmas_resampled, x=\"Date\", y=\"Number of Tweets\", markers=True)\n",
    "lp.xaxis.set_major_locator(mdates.DayLocator())\n",
    "lp.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "lp.xaxis.set_minor_locator(mdates.HourLocator())\n",
    "#lp.xaxis.set_minor_formatter(mdates.DateFormatter('%H'))\n",
    "lp.tick_params(axis=\"x\", which=\"major\", pad=12)\n",
    "lp.grid(b=True, which='minor', color='w', linewidth=0.5)\n",
    "for label in (lp.get_xticklabels() + lp.get_yticklabels()):\n",
    "    label.set_fontsize(14)\n",
    "for label in (lp.get_xminorticklabels()):\n",
    "    label.set_fontsize(8)\n",
    "    label.set_rotation(45)\n",
    "g1 = lp.set_title('Volume of #dronecrashmas tweets by hour | 2019').get_figure()\n",
    "g1.savefig(\"Tweets_Hour_Dads.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday','Sunday']\n",
    "tweets_timeline = crashmas.groupby(by=['hour', 'day_of_week'])['created_at'].count()\n",
    "\n",
    "midpoint = (tweets_timeline.values.max() - tweets_timeline.values.min()) / 2\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "plt.title('Tweet Heatmap for #dronecrashmas Discussions', fontsize=24)\n",
    "\n",
    "ax = (sns.heatmap(tweets_timeline.unstack(),\n",
    "                  cmap='coolwarm',\n",
    "                  robust=True,\n",
    "                  center=midpoint,\n",
    "                  xticklabels=days_of_week))\n",
    "\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(20)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.xlabel('Day of the Week', fontsize=24)\n",
    "plt.ylabel('Time GMT -5:00', fontsize=24)\n",
    "ax.get_figure().savefig('heatmap_drones.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs, Users, and Hashtags\n",
    "This code no longer works. Whether it is user error or a change in how twitter nests arrays, I need further time to fix it. It is supposed to take MongoDB documents containing nested data and flatten them, using json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_flat = json_normalize(df['entities'])\n",
    "entities_data = json_normalize(df['entities'], record_path='urls', meta=['hashtags', 'user_mentions'], errors='ignore')\n",
    "entities_data['protocol'],entities_data['domain'],entities_data['path'],entities_data['query'],entities_data['fragment'] = zip(*[urlsplit(x) for x in entities_data['expanded_url']])\n",
    "df['domain'] = entities_data['domain']\n",
    "df['url'] = entities_data['expanded_url']\n",
    "entities_data.drop(entities_data.index, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_urls = pd.DataFrame()\n",
    "parsed_urls = df['domain'].reset_index(name='url')\n",
    "unique = parsed_urls.groupby('url')['index'].nunique()\n",
    "unique.nlargest(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = pd.DataFrame()\n",
    "url = df['url'].reset_index()\n",
    "url = url.groupby('url')['index'].nunique()\n",
    "url_list = url.nlargest(50).reset_index()\n",
    "url_list.to_csv('top50URLs.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_flat = json_normalize(df['user'])\n",
    "df['screen_name'] = user_flat['screen_name']\n",
    "user_flat.drop(user_flat.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_count = pd.DataFrame()\n",
    "user_count = df['screen_name'].reset_index(name='Screen Name')\n",
    "user_count = user_count.groupby('Screen Name')['index'].nunique()\n",
    "user_count.nlargest(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_data = json_normalize(df['entities'], record_path='hashtags', meta=['user_mentions', 'urls'], errors='ignore')\n",
    "df['hashtags'] = hashtag_data['text']\n",
    "hashtag_data.drop(hashtag_data.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_data = json_normalize(df['entities'], record_path='hashtags', meta=['user_mentions', 'urls'], errors='ignore')\n",
    "hashtags = pd.DataFrame()\n",
    "hashtags = hashtag_data['text'].reset_index(name='hashtags')\n",
    "utags = hashtags.groupby('hashtags')['index'].nunique()\n",
    "utags.nlargest(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
